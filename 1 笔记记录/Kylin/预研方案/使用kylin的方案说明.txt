数据使用场景说明

1、第一个特点是数据规模和模型特点。
	1.1 从数据规模上来讲，事实表的数据级别，同时还有维表的数据量级，也就是超高基数的维表。
	1.2 数据模型是一开始遇到的最大困难。因为Kylin最初的设计是基于一个星形模型的，但很不幸由于各种原因，很多数据都是雪花的模型，还有其它的模型，
		比如所谓“星座”模型，也就是中间是两张或者三张事实表，周围关联了其它很多维表。业务逻辑决定了这些数据的关联方式非常复杂，根本无法用经典标准的理论来解释。

2、第二个是维度
	维度最理想的情况是固定的，每天变化的只是事实表。但实际上维度经常会变，这可能和行业特点有关，比如组织架构，相关的维度数据可能每天都会变化。
	除此之外还可能要用今天的维度去关联所有的历史数据，因此要重刷历史数据，相应的开销也比较大。

3、第三个是数据回溯的问题。
	比如发现数据生成有问题，或者上游出错了，此时就需要重跑数据。这也是和经典理论模型有区别的。

	一个特点是一般都会有一个日期维度，有可能是当天，也有可能是一个星期，一个月，或者任意一个时间段。
	另外也会有较多的层次维度，比如组织架构从最上面的大区一直到下面的蜂窝，就是一个典型的层次维度。

接入Apache Kylin的解决方案
1、最重要的第一点，就是采用宽表。
所有非标准星型的数据模型，都可以通过预处理先拉平，做成一个宽表来解决。
只要能根据业务逻辑把这些表关联起来，生成一张宽表，然后再基于这张表在Kylin里做数据的聚合就可以了。
宽表不只能解决数据模型的问题，还能解决维度变化、或者超高基数的维度等问题。

2、第二点是表达式指标的问题，也可以通过提前处理解决。把表达式单独转成一列，再基于这列做聚合就可以了。实际上宽表和表达式变换的处理可以用hive的view，也可以生成物理表。 

参考地址：http://www.infoq.com/cn/articles/kylin-apache-in-meituan-olap-scenarios-practice




